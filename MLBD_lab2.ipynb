{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "oqXSZYi-4cX4"
   },
   "source": [
    "# MLBD / Lab 2 / Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "cUimpZUk4cX7"
   },
   "source": [
    "## Report submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "ykYbbgn64cX9"
   },
   "source": [
    "This laboratory will be graded, so you have to submit a report. You can work in groups of up to 2 persons and submit a report for each group with the following constraints :\n",
    "\n",
    "- the report must be **AT MOST** 4 pages\n",
    "- it should contain answer to the questions asked in this notebook\n",
    "- it should contain an explanation of the feature you implemented with an overview of how it works (e.g., show some examples) and why you think it is useful\n",
    "- include your results (either as classification report or confusion matrix) for the kNN classifier\n",
    "- include the parameters you chose for the knn (value of k) and why you chose it.\n",
    "- include an analysis of your results\n",
    "\n",
    "Also include a copy of your scripts (.ipynb or .py) that you used WITHOUT the data. The grading will **ONLY be based on the report** and if we have to look at your scripts to understand what you did, it's a bad sign.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "2XBEbqxT4cYC"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "1xzZTCuM4cYG"
   },
   "source": [
    "In this laboratory, we will work with images of plant leaves. The goal is to identify the plant species from the image.\n",
    "\n",
    "To do so, we will use some concepts that have been presented in the theoretical part of the course :\n",
    "- Feature extraction to turn an image into a vector of features\n",
    "    - This will involve using PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "vxpIOq1o4cYM"
   },
   "source": [
    "### Dataset information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "5LCv8jWt4cYP"
   },
   "source": [
    "We will use the ImageClef 2012 Plant classification dataset. To simplify things, we have already extracted a small part of the dataset that we will be working on (in the \"data/preprocessed\" directory).\n",
    "\n",
    "The notebook additionals/lab2_preprocess contains the preprocessing code (background substraction, image size normalization) that was used to create the subset of the data used in this laboratory.\n",
    "\n",
    "Note that **it is not required** to download the full dataset. Neither do you need to run the lab2_preprocess notebook as this has already been done for you. But you can have a look if you are interested.\n",
    "\n",
    "The full dataset can be downloaded from : \n",
    "\n",
    "http://www.imageclef.org/2012/plant\n",
    "\n",
    "The direct link is :\n",
    "\n",
    "http://otmedia.lirmm.fr/LifeCLEF/ImageCLEF2011-2012-2013/ImageCLEF2012PlantIdentificationTaskFinalPackage.zip\n",
    "\n",
    "It is interesting to download this dataset and have a look at the files in *data/SomeStatAndHtmlViewBySpecies/TrainAndTestViewsBySpecies*, which gives a nice overview of the type of plants in the dataset.\n",
    "\n",
    "This dataset was originally used in a challenge. In the *OralPresentationsAndPosters* directory, there are some presentations from the teams that participated in the challenge with information about the type of preprocessing, features and classifiers used. This is very interesting if you are looking for inspiration about what you could implement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "0RPcJPxb4cYW"
   },
   "source": [
    "### Note about OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "kV8d1RJi4cYY"
   },
   "source": [
    "We will use the OpenCV image processing library to extract some features from the images. If it is not already done, you can install it using anaconda with the following command :\n",
    "\n",
    "    $ conda install opencv\n",
    "    \n",
    "You should then be able to import the OpenCV python module, called **cv2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "-j_7hKK-4cYd"
   },
   "outputs": [
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import numpy.linalg as la\n",
    "import skimage\n",
    "import skimage.io\n",
    "from matplotlib import pyplot as pl\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=5, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "aDddpgQQ4cYb"
   },
   "source": [
    "## Dataset overview\n",
    "Before doing this step you must copy the compressed file \"ImageCLEF_DB.zip\" data in the colab space:\n",
    "### left panel -> Files ->UPLOAD\n",
    "Or uncomment the following cell if you copied the data to your drive account\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "G2KDxUB7Geul",
    "outputId": "9e58a72b-403c-45fd-f073-86efaaf5b82c"
   },
   "outputs": [
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#!ls 'drive/My Drive/MSE/semester_2/mldb/labo_2'\n",
    "#!cp 'drive/My Drive/MSE/semester_2/mldb/labo_2/imageCLEF_DB.zip' ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Tx4NXiZH99uq",
    "outputId": "d0025fc9-bcdb-4a47-b7b0-f3abfe02ee10"
   },
   "outputs": [
   ],
   "source": [
    "if os.path.exists('imageCLEF_DB'):\n",
    "    print('Data are already in folder')\n",
    "else:\n",
    "    if os.path.exists('imageCLEF_DB.zip'):\n",
    "        !unzip imageCLEF_DB.zip\n",
    "    else:\n",
    "        print('You must upload the data first!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "GcPLv2t64cYl"
   },
   "outputs": [
   ],
   "source": [
    "DIR = 'imageCLEF_DB/data/preprocessed/'\n",
    "meta = pd.io.pickle.read_pickle(os.path.join(DIR, 'meta.pkl'))\n",
    "\n",
    "def load_img(name):\n",
    "    \"\"\"Loads the given image by name and returns a masked array\"\"\"\n",
    "    img = skimage.io.imread(os.path.join(DIR, 'imgs', name + \".png\"))\n",
    "    img = skimage.img_as_float(img)\n",
    "    img = ma.masked_where(img == 0, img)\n",
    "    # same mask for all 3 axes\n",
    "    mask = np.all(img == 0, axis=2)\n",
    "    img = ma.array(img)\n",
    "    for i in range(img.shape[2]):\n",
    "        img.mask[:,:,i] = mask\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "scf1Ac_X4cYs"
   },
   "source": [
    "The meta dataframe contains information for each image :\n",
    "\n",
    "- *basename* is the filename (without extension) of the image.\n",
    "- *content* gives information about the image content. To simplify the problem, we selected only images of plant leaves on uniform backgrounds, but the original dataset has more variety. \n",
    "- *classid* is the class. We selected 9 classes from the original dataset.\n",
    "- *photo_type* is the type of photo. To simplify, we used only scan and pseudoscan (=uniform background) images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "5vE3qQkR4cY2",
    "outputId": "fae2a36c-481e-439b-f842-9cc52e665cbf"
   },
   "outputs": [
   ],
   "source": [
    "meta.iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "8BhWRBWs4cY7"
   },
   "source": [
    "You can use the *load_img* function to load an image.\n",
    "\n",
    "** Masked arrays: ** Notice that we are using [numpy *masked* arrays](http://docs.scipy.org/doc/numpy/reference/maskedarray.html), which are a special type of numpy array that have a mask. The mask is a boolean array that indicates if an entry is valid (mask[i,j] == False) or invalid (mask[i,j] == True). For our images, the background pixels are all masked. You can access the mask by using the .mask attribute of the array. Below, we use img.filled(1) to get a copy of the array with masked values replaced by 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "3-ZatA9H4cY8",
    "outputId": "8c609fe0-8220-4f7a-d610-b4b2023d18d9"
   },
   "outputs": [
   ],
   "source": [
    "# Show 3 example images\n",
    "examples = [0, 50, 300]\n",
    "\n",
    "pl.figure(figsize=(10, 3))\n",
    "for i, idx in enumerate(examples): \n",
    "    pl.subplot(1, 3, i + 1)\n",
    "    img = load_img(meta.iloc[idx]['basename'])\n",
    "    pl.title(meta.iloc[idx]['classid'])\n",
    "    pl.imshow(img.filled(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "7-vHPEPd4cZJ",
    "outputId": "c3b2267f-aa7d-43cc-910f-1c9abadd9c12"
   },
   "outputs": [
   ],
   "source": [
    "# The classes we will work with\n",
    "print(np.unique(meta['classid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "06IoSTzb4cZe",
    "outputId": "b399eedd-fd0e-4ea1-9206-7a4c32d6c7de"
   },
   "outputs": [
   ],
   "source": [
    "# You can plot some examples images for a given species\n",
    "import random\n",
    "examples = np.flatnonzero(meta['classid'] == 'vitex agnus-castus')\n",
    "\n",
    "for idx in random.sample(list(examples), 3):\n",
    "    pl.figure()\n",
    "    img = load_img(meta.iloc[idx]['basename'])\n",
    "    pl.title(meta.iloc[idx]['classid'])\n",
    "    pl.imshow(img.filled(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "X08gnfEH4cZi"
   },
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "KfK91fQ14cZi"
   },
   "source": [
    "So, we have images of leaves and we want to train a classifier to automatically determine the species of a leaf.\n",
    "\n",
    "What should we use as input vectors for our classifier ?\n",
    "\n",
    "The bruteforce approach could be to use a flattened version of all the image pixels (you concatenate all the rows in the image). Since we have images that have a size of 512x512, this would result in 262144 (512*512) dimensional input vectors.\n",
    "\n",
    "For most classifiers, this is way too much dimensions. Also, this would mean that if you translate your image by one pixel, the input vector will change dramatically. Later in the course, we will see that deep learning classifiers are able to use data in such an unprocessed form, but for now, we have to extract features.\n",
    "\n",
    "The better approach is to extract features to represent each image. If we ask you to manually classify those images, what will you look at ? Color ? The general shape of the leaf (i.e. elongated, round) ? The texture of the leaf ?\n",
    "\n",
    "We will try to extract features that allow our classifier to use the same kind of hints that a human would use. We will start with two features : *eccentricity* and *curvature*. You will then have to propose and implement a new feature and see how the new information impacts classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "r1Wy79gr4cZi"
   },
   "source": [
    "First, we define some utility functions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "kFORlWBE4cZj"
   },
   "outputs": [
   ],
   "source": [
    "def get_plant_points(img):\n",
    "    \"\"\"\n",
    "    Given the image of a plant, returns a Nx2 array containing the (x, y) coordinate\n",
    "    of all non-masked points\n",
    "    \"\"\"\n",
    "    # this returns (y, x) tuple\n",
    "    points = np.transpose(np.nonzero(~img.mask)[:2])\n",
    "    # makes that an (x, y) tuple\n",
    "    points = np.roll(points, 1, axis=1)\n",
    "    return points\n",
    "\n",
    "def extract_contour(img):\n",
    "    \"\"\"\n",
    "    Wrapper around OpenCV's contour extraction methods. This returns only the longest\n",
    "    contour\n",
    "    \"\"\"\n",
    "    _, contours, hierarchy = cv2.findContours(\n",
    "        skimage.img_as_ubyte(~img.mask[:,:,0]),\n",
    "        cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_NONE\n",
    "    )\n",
    "\n",
    "    # only take longest contour into account\n",
    "    longest_contour = np.argmax([len(c) for c in contours])\n",
    "    cnt = contours[longest_contour]\n",
    "    cnt = np.squeeze(cnt)\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "bGqRXtmD4cZk"
   },
   "source": [
    "### Eccentricity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "Yf_8cxpR4cZl"
   },
   "source": [
    "Eccentricity gives us information about how the distribution of the leaf points deviates from a perfect circle.\n",
    "\n",
    "The *get_plant_points* method above gives us the coordinate $(x, y)$ of all foreground (non-masked) points in the image. If we perform PCA on those points, we get two orthogonal (uncorrelated) principal axis (components) which are :\n",
    "\n",
    "- The first axis is the axis with maximum variance\n",
    "- The second axis is orthogonal to the first\n",
    "\n",
    "In addition, each axis (which are the eigenvectors of the covariance matrix of our data) has an associated eigenvalue. The eigenvalue informs us about the relative importance of each axis.\n",
    "\n",
    "We compute the eccentricity as the ratio of the eigenvalues of the two axis. If our points are distributed in a perfect circle, both axes will have equal importance and the ratio will be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "bO-67Ol-4cZl"
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def eccentricity(img, plot=False):\n",
    "    \"\"\"Compute eccentricity : the ratio of the eigenvalues of principal components\"\"\"\n",
    "    points = get_plant_points(img)\n",
    "    pca = PCA(n_components=2).fit(points)\n",
    "    centroid = pca.mean_\n",
    "    eccentricity = pca.explained_variance_[0] / pca.explained_variance_[1]\n",
    "\n",
    "    if plot:\n",
    "        pl.title('eccentricity : %f' % eccentricity)\n",
    "        pl.imshow(img)\n",
    "\n",
    "        # direction of the two principal components\n",
    "        d1 = pca.components_[0,:]\n",
    "        d2 = pca.components_[1,:]\n",
    "\n",
    "        scale = 100\n",
    "        p1 = centroid + scale * d1 * pca.explained_variance_ratio_[0]\n",
    "        pl.plot([centroid[0], p1[0]], [centroid[1], p1[1]], c='r')\n",
    "\n",
    "        p2 = centroid + scale * d2 * pca.explained_variance_ratio_[1]\n",
    "        pl.plot([centroid[0], p2[0]], [centroid[1], p2[1]], c='y')\n",
    "\n",
    "        pl.xlim((0, img.shape[1]))\n",
    "        pl.ylim((img.shape[0], 0))\n",
    "\n",
    "    return eccentricity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "xgPF2HpK4cZo"
   },
   "source": [
    "First, let's play with circles and ellipses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "b-WCwUO64cZo",
    "outputId": "6b24e339-3f61-4a2d-8b6a-a120c0eb9412"
   },
   "outputs": [
   ],
   "source": [
    "import skimage.draw\n",
    "\n",
    "def get_ellipse_image(yradius, xradius):\n",
    "    img = ma.masked_all((512, 512), dtype=np.float)\n",
    "    rr, cc = skimage.draw.ellipse(256, 256, r_radius=yradius, c_radius=xradius, shape=(512, 512))\n",
    "    img[rr, cc] = 1\n",
    "    return img\n",
    "\n",
    "pl.figure(figsize=(8, 3))\n",
    "pl.subplot(121)\n",
    "# This is a circle\n",
    "eccentricity(get_ellipse_image(64, 64), plot=True)\n",
    "\n",
    "pl.subplot(122)\n",
    "# An ellipse\n",
    "eccentricity(get_ellipse_image(128, 64), plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "-TkJFPCp4cZv"
   },
   "source": [
    "Ok so now we can apply eccentricity on our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "8_lO6dx-4cZw",
    "outputId": "370c2752-71c9-411a-ee34-2ad6df5818d3"
   },
   "outputs": [
   ],
   "source": [
    "examples = [0, 50, 300]\n",
    "pl.figure(figsize=(10, 3))\n",
    "for i, idx in enumerate(examples): \n",
    "    pl.subplot(1, 3, i + 1)\n",
    "    print(meta.iloc[idx])\n",
    "    img = load_img(meta.iloc[idx]['basename'])\n",
    "    eccentricity(img, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "oRFKQ3664cZy"
   },
   "source": [
    "### Curvature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "VY6MoqyV4cZy"
   },
   "source": [
    "We will compute the [curvature](http://en.wikipedia.org/wiki/Curvature#Curvature_of_plane_curves) of the contour of the leaf. This will help describe the \"pointiness\" of the contour.\n",
    "\n",
    "The function does the following steps :\n",
    "\n",
    "- Extract the leaf contour (using OpenCV's contour extraction functions).\n",
    "- Compute the curvature for each point on the contour.\n",
    "- Compute an histogram of all the curvatures of contour points.\n",
    "\n",
    "The final feature vector will be the histogram. The number of bins in the histogram define the dimensionality of the feature vector.\n",
    "\n",
    "There are three parameters that are important when computing our curvature feature :\n",
    "\n",
    "- *step* : To compute curvature for a given point, we need a previous and next point and then use those 3 points to construct a circumcircle, the (inverse of the) radius of which is the curvature. The step determine how far away we pick our previous and next point.\n",
    "\n",
    "<img width=\"200px\" src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Osculating_circle.svg/460px-Osculating_circle.svg.png\" />\n",
    "\n",
    "- *nbins* and *vmax* : When computing our histogram of curvatures, we have to decide the number of bins in the histogram. We also have to decide the range of the bins, which will be in [0, vmax] . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "VBca0s4P4cZ1"
   },
   "outputs": [
   ],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "def circumcircle_radius(p1, p2, p3):\n",
    "    \"\"\"\n",
    "    Given 3 points of a triangle, computes the radius of the circumcircle\n",
    "    http://www.mathopenref.com/trianglecircumcircle.html\n",
    "\n",
    "    This function can return np.inf if the triangle has an area of zero\n",
    "    \"\"\"\n",
    "    a = la.norm(p2 - p1)\n",
    "    b = la.norm(p3 - p2)\n",
    "    c = la.norm(p1 - p3)\n",
    "    #print a, b, c\n",
    "\n",
    "    # Check for degenerate case (triangle has an area of zero)\n",
    "    denom = np.fabs((a+b+c)*(b+c-a)*(c+a-b)*(a+b-c))\n",
    "    if abs(denom) < 1e-5:\n",
    "        return np.inf\n",
    "    else:\n",
    "        r = (a * b * c)/np.sqrt(denom)\n",
    "        return r\n",
    "\n",
    "def curvature_from_cnt(line, step=10):\n",
    "    \"\"\"\n",
    "    Curvature computation for a line given as a Nx2 array\n",
    "    We assumes the line is closed (ie the last and first point are contiguous)\n",
    "\n",
    "    Each set of 3 consecutive (see step) points on the line forms a triangle\n",
    "    and the radius of the circumcircle of this triangle is the radius of\n",
    "    the curve for that set. The curvature is 1/r where r is this radius.\n",
    "\n",
    "    Taking immediatly consecutive points doesn't work well, so `step` specify\n",
    "    how points triplets are formed : (i-step, i, i+step)\n",
    "    \"\"\"\n",
    "    # Append line end at beginning and beginning at end to simulate closed\n",
    "    # line\n",
    "    l = np.r_[line[-1].reshape(-1, 2),\n",
    "              np.array(line),\n",
    "              line[0].reshape(-1, 2)]\n",
    "    curv = []\n",
    "    linelen = line.shape[0]\n",
    "    for i in range(linelen):\n",
    "        # indices in l are shifted by -1\n",
    "        #r = circumcircle_radius(l[i], l[i+1], l[i+2])\n",
    "        r = circumcircle_radius(line[(i-step)%linelen],\n",
    "                                line[i],\n",
    "                                line[(i+step)%linelen])\n",
    "        if np.isinf(r):\n",
    "            # Flat => curvature = 0\n",
    "            curv.append(0)\n",
    "        else:\n",
    "            curv.append(1.0 / r)\n",
    "    return np.array(curv)\n",
    "\n",
    "def curvature(img, step=10, plot=False, gs=None):\n",
    "    cnt = extract_contour(img)\n",
    "\n",
    "    cvt = curvature_from_cnt(cnt, step=step)\n",
    "\n",
    "    if plot:\n",
    "        if gs is None:\n",
    "            gs = gridspec.GridSpec(1, 2)\n",
    "        vimg = skimage.img_as_ubyte(img)\n",
    "        cv2.drawContours(vimg, [cnt], 0, (0,255,0), 3)\n",
    "\n",
    "        pl.subplot(gs[0])\n",
    "        pl.title('contour')\n",
    "        pl.imshow(vimg)\n",
    "        pl.axis('off')\n",
    "\n",
    "        pl.subplot(gs[1])\n",
    "        pl.title('curvature')\n",
    "        pl.imshow(img)\n",
    "        pl.scatter(cnt[:,0], cnt[:,1], c=cvt, linewidths=0, s=5)\n",
    "        pl.xlim((0, img.shape[1]))\n",
    "        pl.ylim((img.shape[0], 0))\n",
    "        pl.axis('off')\n",
    "\n",
    "    return cvt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "421215uj4cZ2"
   },
   "source": [
    "## Q: Implement the curvature_hist function\n",
    "\n",
    "This function should take an image as input and return a vector of dimension $n$ representing the histogram of contour curvatures for the given image with $n$ bins. The signature should be :\n",
    "\n",
    "    def curvature_hist(img, step=10, plot=False):\n",
    "        # implement here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "3Fd3foFD4cZ3"
   },
   "outputs": [
   ],
   "source": [
    "#\n",
    "# Your curvature_hist code here\n",
    "#\n",
    "def curvature_hist(img, step=10, plot=False):\n",
    "    n_bins = 10\n",
    "    bin_width = 0.03\n",
    "    x_start = 0\n",
    "    x_end = 0.5\n",
    "\n",
    "    curvatures = curvature(img, step=step)\n",
    "    bins = np.linspace(x_start, x_end, n_bins+1)\n",
    "    res, _ = np.histogram(curvatures, bins=bins, range=(x_start, x_end))\n",
    "    res = res / float(len(curvatures))\n",
    "\n",
    "    if plot:\n",
    "        pl.title('Curvatures\\' Histogram')\n",
    "        pl.bar(bins[1:], res, width=bin_width)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "M0Qw13Qh4cZ4",
    "outputId": "8ac8b81d-6be4-46f8-ba38-e2e3ae617384"
   },
   "outputs": [
   ],
   "source": [
    "m1 = meta['classid'] == 'alnus glutinosa'\n",
    "m2 = meta['classid'] == 'acer campestre'\n",
    "print(np.flatnonzero(m1))\n",
    "print(np.flatnonzero(m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1073
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "wQN-ymNe4cZ7",
    "outputId": "8f165ac8-fa45-43d2-bcc0-f357391af123"
   },
   "outputs": [
   ],
   "source": [
    "examples = [1, 13, 7]\n",
    "#examples = [19, 44, 3, 6]\n",
    "for i, idx in enumerate(examples):\n",
    "    pl.figure(figsize=(10, 5))\n",
    "    img = load_img(meta.iloc[idx]['basename'])\n",
    "    c = curvature_hist(img, step=10, plot=True)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "QVRlxO6U4cZ9"
   },
   "source": [
    "### Implement your own features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "bxLqcNJy4cZ-"
   },
   "source": [
    "http://www.math.uci.edu/icamp/summer/research_11/park/shape_descriptors_survey.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "vktgsmL24caA"
   },
   "source": [
    "## Q: Implement a new feature</p>\n",
    "\n",
    "Implement a new feature extractor that you think could be useful for this classification task. Explain why your feature extractor is useful. You can look at the presentations accompanying the original dataset for inspiration. You can also start building on the convex hull example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "IqJntbgJ4caB",
    "outputId": "27dcd7b8-3aa3-4e85-8360-3bd1ad0eea0c"
   },
   "outputs": [
   ],
   "source": [
    "# As an example, OpenCV allows you to compute the convex hull of a shape. An idea of feature might be\n",
    "# to compute the ratio of area covered by valid pixels versus the convex hull area\n",
    "cnt = extract_contour(img)\n",
    "hull = cv2.convexHull(cnt)\n",
    "vimg = skimage.img_as_ubyte(img)\n",
    "cv2.drawContours(vimg, [hull], 0, (0,255,0), -1)\n",
    "pl.imshow(vimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "6p62nO_cfD3q"
   },
   "outputs": [
   ],
   "source": [
    "idx = 8\n",
    "img = load_img(meta.iloc[idx]['basename'])\n",
    "\n",
    "def hull_concave_ratio(img, plot = False):\n",
    "    p = get_plant_points(img)\n",
    "    cnt = extract_contour(img)\n",
    "    hull = cv2.convexHull(cnt)\n",
    "\n",
    "    if plot:\n",
    "        pl.figure(figsize=(10, 3))\n",
    "        vimg = skimage.img_as_ubyte(img)\n",
    "        contourImg = vimg.copy()\n",
    "        cv2.drawContours(vimg, [hull], 0, (0,255,0), -1)\n",
    "        cv2.drawContours(contourImg, [cnt], 0, (0,255,0), -1)\n",
    "        pl.subplot(1, 3, 1)\n",
    "        pl.title('Original')\n",
    "\n",
    "        pl.imshow(img.filled(1))\n",
    "        pl.subplot(1, 3, 2)\n",
    "        pl.title('Contour')\n",
    "\n",
    "        pl.imshow(contourImg)\n",
    "        pl.subplot(1, 3, 3)\n",
    "        pl.title('Convex hull')\n",
    "\n",
    "        pl.imshow(vimg)\n",
    "\n",
    "    return cv2.contourArea(hull)/cv2.contourArea(cnt)\n",
    "\n",
    "hull_concave_ratio(img, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "uG4wdC2W4caJ"
   },
   "source": [
    "<p style=\"background-color:#660066; color:#fff;padding:5px; font-weight:bold\">Q: Use the features to train and evaluate a k-NN classifier</p>\n",
    "\n",
    "This involves :\n",
    "\n",
    "- Compute the feature vector of each image (by concatenating individual features of the image).\n",
    "- Build a $n$ x $m$ data matrix $X$ with the feature vectors of all the images, where $n$ is the number of images and $m$ the number of features.\n",
    "- Build an integer vector of length $n$, $y$, containing the target class for each image. *sklearn.preprocessing.LabelEncoder* is useful for converting text labels into integers.\n",
    "- Split your dataset into training and test : X_train, X_test, y_train, y_test. *sklearn.cross_validation* has useful utility functions for that.\n",
    "- Normalizing your data. *sklearn.preprocessing.MinMaxScaler* might be useful (or other similar scaler classes)\n",
    "- Build a classifier with *sklearn.neighbors.KNeighborsClassifier* on your training dataset and evaluate on your test dataset.\n",
    "    - this the *y_pred = knn.predict(X_test)* cell\n",
    "\n",
    "After you have evaluated your model **write a short analysis of your results**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Tg6veWnA4caK"
   },
   "outputs": [
   ],
   "source": [
    "#\n",
    "# Your KNN code here\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "KQXuzXROkbby"
   },
   "outputs": [
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def label_encoder(meta):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    classids = {}\n",
    "\n",
    "    for i in range(0, len(meta)-1):\n",
    "        elem = meta.iloc[i]\n",
    "        if not elem['classid'] in classids :\n",
    "            classids[elem['classid']] = True\n",
    "\n",
    "    le.fit([*classids.keys()])\n",
    "    return le\n",
    "\n",
    "labelEncoder = label_encoder(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "cfdZ_t8vO9oh"
   },
   "outputs": [
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import neighbors\n",
    "\n",
    "def extract_dataset(meta, labelEncoder):\n",
    "    features = np.zeros((len(meta), 12))\n",
    "    classes = np.zeros((len(meta), 1))\n",
    "\n",
    "    for i in range(0, len(meta)-1):\n",
    "        elem = meta.iloc[i]\n",
    "        features[i,:] = extract_features(elem)\n",
    "        classes[i,:] = labelEncoder.transform([elem['classid']])\n",
    "\n",
    "    return normalize( features ), classes\n",
    "\n",
    "def extract_features(meta_elem):\n",
    "    img = load_img(meta_elem['basename'])\n",
    "    res = np.zeros((1,12))\n",
    "    res[0,0:10] = curvature_hist(img).reshape((1,10))\n",
    "    res[0,10] = hull_concave_ratio(img)\n",
    "    res[0,11] = eccentricity(img)\n",
    "    return res\n",
    "\n",
    "def normalize(features):\n",
    "    nbi, nbf = features.shape\n",
    "    res = np.zeros((nbi,nbf))\n",
    "    for i in range(0,nbf-1):\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        scaler.fit(features[:,i].reshape(-1, 1))\n",
    "        res[:,i] = scaler.transform(features[:,i].reshape(1, -1))\n",
    "    return res\n",
    "\n",
    "features, classes = extract_dataset(meta, labelEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "frEqyKqPR194",
    "outputId": "2caa3b9c-42d5-4ba0-d032-aa22b607b91d"
   },
   "outputs": [
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(normalize(features), classes, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "frEqyKqPR194",
    "outputId": "2caa3b9c-42d5-4ba0-d032-aa22b607b91d"
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracies = []\n",
    "# Try to find best K\n",
    "for k in range (1, 10):\n",
    "            knn = neighbors.KNeighborsClassifier(n_neighbors = k)\n",
    "            knn.fit(X_train, y_train[:,0])\n",
    "            y_pred = knn.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            accuracies.append((accuracy, k))\n",
    "\n",
    "accuracies.sort(reverse=True)\n",
    "print(\"Top 3 tuples: {}\\n{}\\n{}\\n\".format(accuracies[0],accuracies[1],accuracies[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "frEqyKqPR194",
    "outputId": "2caa3b9c-42d5-4ba0-d032-aa22b607b91d"
   },
   "outputs": [
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "UBLKoFAK4caM"
   },
   "outputs": [
   ],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "di4KPnds4caP",
    "outputId": "8bb5b4f4-08b1-4bd5-c128-1f18b6f8130f"
   },
   "outputs": [
   ],
   "source": [
    "# performance evaluation.                        - for lencoder see sklearn.preprocessing.LabelEncoder\n",
    "import sklearn.metrics as skmetrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "lencoder = labelEncoder # confused about why this variable changed its name now...\n",
    "report = skmetrics.classification_report(y_test, y_pred,\n",
    "                                         labels=np.arange(len(lencoder.classes_)),\n",
    "                                         target_names=lencoder.classes_)\n",
    "confmat = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "staI59Hc4caQ"
   },
   "outputs": [
   ],
   "source": [
    "def plot_confusion_matrix(confmat, labels_names, ax=None, cmap=None):\n",
    "    \"\"\"Utility function to plot a confusion matrix\"\"\"\n",
    "    if ax is None:\n",
    "        ax = pl.subplot(111)\n",
    "    cmim = ax.matshow(confmat, interpolation='nearest', cmap=cmap)\n",
    "\n",
    "    for i in range(confmat.shape[0]):\n",
    "        for j in range(confmat.shape[1]):\n",
    "            ax.annotate(str(confmat[i, j]), xy=(j, i),\n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center',\n",
    "                        fontsize=8)\n",
    "    ax.set_xticks(np.arange(confmat.shape[0]))\n",
    "    ax.set_xticklabels([labels_names[l] for l in range(confmat.shape[0])], rotation='vertical')\n",
    "    ax.set_yticks(np.arange(confmat.shape[1]))\n",
    "    _ = ax.set_yticklabels([labels_names[l] for l in range(confmat.shape[1])])\n",
    "    ax.set_xlabel('predicted label')\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.set_ylabel('true label')\n",
    "    pl.colorbar(cmim, shrink=0.7, orientation='horizontal', pad=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "kmEW0GNX4caS",
    "outputId": "f63695ab-ad12-40ea-d9ae-ba5f795c7bee"
   },
   "outputs": [
   ],
   "source": [
    "pl.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(confmat, lencoder.classes_, cmap=cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "L9988WZ64caU",
    "outputId": "7df2c3c9-7874-4400-c513-b19b2f57f1d1",
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "21l4EtDbO9ou",
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# MLP using scikit\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Try to find best number of neurons\n",
    "for i in range (1, 10):\n",
    "    for j in range (1,10):\n",
    "            clf = MLPClassifier(activation='tanh', solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(i,j), random_state = 1)\n",
    "            clf.fit(X_train, y_train[:,0])\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            #print(\"For values hidden layer values of {},{}: result {}\".format(i,j, accuracy))\n",
    "            accuracies.append((accuracy, (i,j)))\n",
    "\n",
    "accuracies.sort(reverse=True)\n",
    "print(\"Top 5 tuples: {}\\n{}\\n{}\\n{}\\n{}\\n\".format(accuracies[0],accuracies[1],accuracies[2],accuracies[3],accuracies[4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "clf = MLPClassifier(activation='tanh', solver='lbfgs', alpha=1e-4, hidden_layer_sizes=accuracies[0][1], random_state = 1)\n",
    "clf.fit(X_train, y_train[:,0])\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "report = skmetrics.classification_report(y_test, y_pred,\n",
    "                                         labels=np.arange(len(lencoder.classes_)),\n",
    "                                         target_names=lencoder.classes_)\n",
    "confmat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "pl.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(confmat, lencoder.classes_, cmap=cm.gray_r)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Expected TODO\n",
    "\n",
    "- the report must be **AT MOST** 4 pages\n",
    "- it should contain answer to the questions asked in this notebook\n",
    "- it should contain an explanation of the feature you implemented with an overview of how it works (e.g., show some examples) and why you think it is useful\n",
    "- include your results (either as classification report or confusion matrix) for the kNN classifier\n",
    "- include the parameters you chose for the knn (value of k) and why you chose it.\n",
    "- include an analysis of your results\n",
    "\n",
    "Also include a copy of your scripts (.ipynb or .py) that you used WITHOUT the data. The grading will **ONLY be based on the report** and if we have to look at your scripts to understand what you did, it's a bad sign.\n",
    "\n",
    "############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Explain the implemented features and how it's useful\n",
    "### curvature_hist\n",
    "### hull_concave_ratio\n",
    "\n",
    "## kNN Results (classification report and confusion matrix)\n",
    "\n",
    "## Explain the kNN parameters why chose those\n",
    "\n",
    "## MLP Results\n",
    "\n",
    "## Explain the MLP paramters why chose those\n",
    "\n",
    "## Analysis of the results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "cUimpZUk4cX7"
   ],
   "name": "MLBD_lab2_2.ipynb",
   "provenance": [
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}