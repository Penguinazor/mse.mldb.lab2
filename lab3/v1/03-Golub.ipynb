{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection lab - Golub\n",
    "Lab developed by Gary Marigliano - 07.2018\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we are going to use the Golub dataset which contains about 7000 features, 72 samples and 2 classes (AML and ALL). \n",
    "\n",
    "The goal is to get lists of relevant features (100 or less) using several FS techniques. The idea is to combine several lists of features to get \"super\" lists that should (maybe) perform better than only one list. To merge the lists you are going to be creative (take the union/intersection between all the lists, use the the feature's importance score as a weight or a probability to select this feature from a list,...).\n",
    "\n",
    "## Rules to build a super list\n",
    "\n",
    "* The super list must contain 100 features or less\n",
    "* You are not forced to use all the lists to build the super list\n",
    "* The super list must not contain duplicate features\n",
    "* The super list must at least use features from 2 different FS techniques\n",
    "\n",
    "You can use some features selection algorithms listed here (the python library should already been installed for this project): http://featureselection.asu.edu/html/skfeature.function.html and http://featureselection.asu.edu/tutorial.php\n",
    "\n",
    "\n",
    "## TODO in this notebook\n",
    "\n",
    "Answer the questions in this notebook (where **TODO student** is written)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_classes = preprocessing.LabelEncoder()\n",
    "le_classes.fit([\"AML\", \"ALL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_dataset(filenames, le_classes):\n",
    "    df = pd.read_csv(filenames[0], sep=\"\\t\", usecols=[\"ID_REF\", \"VALUE\"]).transpose().drop(\"ID_REF\", axis=0)\n",
    "    df.index = [filenames[0].split(\"/\")[-1]]\n",
    "\n",
    "    for i in range(1, len(filenames)):\n",
    "        df2 = pd.read_csv(filenames[i], sep=\"\\t\", usecols=[\"ID_REF\", \"VALUE\"]).transpose().drop(\"ID_REF\", axis=0)\n",
    "        df2.index = [filenames[i].split(\"/\")[-1]]\n",
    "\n",
    "        df = pd.concat([df, df2])\n",
    "\n",
    "    X = df.values\n",
    "\n",
    "    y = [fname[-7:-4] for fname in df.index.values]\n",
    "    y = le_classes.transform(y)\n",
    "\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 7129) (38,) (34, 7129) (34,)\n"
     ]
    }
   ],
   "source": [
    "train_filenames = glob.glob(\"./datasets/golub/train/*.csv\")\n",
    "test_filenames = glob.glob(\"./datasets/golub/test/*.csv\")\n",
    "\n",
    "X_train, y_train = parse_dataset(train_filenames, le_classes)\n",
    "X_test, y_test = parse_dataset(test_filenames, le_classes)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AFFX-BioB-5_at' 'AFFX-BioB-M_at' 'AFFX-BioB-3_at' ..., 'L49218_f_at'\n",
      " 'M71243_f_at' 'Z78285_f_at']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(train_filenames[0], sep=\"\\t\", usecols=[\"ID_REF\", \"VALUE\"]).transpose().drop(\"VALUE\", axis=0)\n",
    "features_name = df.values[0]\n",
    "print(features_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO student**\n",
    "\n",
    "* Get 3 super lists using at least 2 different FS techniques. This is an example to build a super list:\n",
    "    * FS techniques: ExtraTrees + Fisher score; Merge technique: intersection of the lists\n",
    "    * FS techniques: Recursive Feature Elimination SVM + ANN + MRMR: pick K features with a probability based on the feature importance's score\n",
    "* For each super list:\n",
    "    * Get the `evaluate_features()` function you wrote in 02-WDBC\n",
    "    * Use this function with the super list\n",
    "    * Use this function with a random list of selected features (same size as the super list)\n",
    "    * Use this function with all the features\n",
    "    * Make a plot similar to the one just below (see https://matplotlib.org/examples/api/barchart_demo.html)\n",
    "    * Comment the results. Here are some clues about the questions you should ask yourself:\n",
    "        * How the scores of the lists of selected features behave compare to the random/all features ?\n",
    "        * How behave the classifiers inside `evaluate_features()` ? Do they prefer a list in general ?\n",
    "        \n",
    "* You may be careful to the following points:\n",
    "   * the classifiers you use may not be determinist therefore you may want to run them multiple time to have an averaged score\n",
    "   * try to choose classifiers that are relatively different regarding how they use the data. Using 3 classifiers that are tree-based is not the best idea you can have\n",
    "   * try to choose classifiers that you didn't use to get the lists of features in the first place\n",
    "\n",
    "* Comment your results. Here are some clues about the questions you should ask yourself:\n",
    "    * What kind of problems could you encounter when merging the lists ?\n",
    "    * Do the super lists that use more lists perform better ?\n",
    "    * What about the execution time ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/02-WDBC-perf-plot.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
